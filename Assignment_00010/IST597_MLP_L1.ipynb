{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597_MLP_L1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_MLP_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import keras\n",
        "import time\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "seed=97238684\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "# np.random.seed(1234)\n",
        "# tf.random.set_seed(1234)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-3kEaggcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdabc26-c477-4c67-ba9d-bd04e646cfa5"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw78jw6pDqSM"
      },
      "source": [
        "#Get number of Gpu's and id's in the system or else you can also use Nvidia-smi in command prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk_S2TMg_6_"
      },
      "source": [
        "## Generate random data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XlFnwho7D8"
      },
      "source": [
        "size_input = 784\n",
        "size_hidden1 = 512\n",
        "size_hidden2 = 256\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "starter_learning_rate = 0.001\n",
        "regularizer_rate = 0.1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm23CzRihaW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f47e19f-4a7d-4cda-837e-8c04c88a4213"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=(1-train_ratio))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=((test_ratio/(validation_ratio+test_ratio))))\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(Xtrain_fmnist, ytrain_fmnist), (Xtest_fmnist, ytest_fmnist) = fashion_mnist.load_data()\n",
        "X_fmnist = np.concatenate([Xtrain_fmnist, Xtest_fmnist])\n",
        "y_fmnist = np.concatenate([ytrain_fmnist, ytest_fmnist])\n",
        "\n",
        "Xtrain_fmnist, X_val_fmnist, ytrain_fmnist, y_val_fmnist = train_test_split(X_fmnist, y_fmnist, test_size=(1-train_ratio))\n",
        "X_val_fmnist, Xtest_fmnist, y_val_fmnist, ytest_fmnist = train_test_split(X_val_fmnist, y_val_fmnist, test_size=((test_ratio/(validation_ratio+test_ratio))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGPxtq-Gb4vx",
        "outputId": "d428c16d-e464-466e-e2ee-eb6219435512"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = np.reshape(X_train, (56000, 784))\n",
        "X_test = np.reshape(X_test, (-1, 784))\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255\n",
        "X_val = np.reshape(X_val, (7000,784))\n",
        "X_val=X_val/255.0\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "y_train = tf.one_hot(y_train,10)\n",
        "y_test = tf.one_hot(y_test,10)"
      ],
      "metadata": {
        "id": "G4ENBZGWb4yV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_fmnist = np.reshape(X_train, (56000, 784))\n",
        "Xtest_fmnist = np.reshape(X_test, (-1, 784))\n",
        "Xtrain_fmnist = Xtrain_fmnist.astype(float) / 255\n",
        "Xtest_fmnist = Xtest_fmnist.astype(float) / 255\n",
        "X_val_fmnist = np.reshape(X_val_fmnist, (7000,784))\n",
        "X_val_fmnist=X_val_fmnist.astype(float) /255.0\n",
        "ytrain_fmnist = tf.one_hot(ytrain_fmnist,10)\n",
        "ytest_fmnist = tf.one_hot(ytest_fmnist,10)"
      ],
      "metadata": {
        "id": "ZlIIRszxb9nN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(Xtrain_fmnist.shape, ytrain_fmnist.shape)\n",
        "print(\"y_train: \",y_train)\n",
        "print(\"y_val: \",y_val)\n",
        "print(\"y_test: \",y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "droiWRYhcBcg",
        "outputId": "a30cdaff-805c-40e6-bb5f-ba5c75fe981b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784) (56000, 10)\n",
            "(56000, 784) (56000, 10)\n",
            "y_train:  tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]], shape=(56000, 10), dtype=float32)\n",
            "y_val:  [4 2 6 ... 6 2 5]\n",
            "y_test:  tf.Tensor(\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]], shape=(7000, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2"
      },
      "source": [
        "# Split MNIST dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split FMNIST dataset into batches\n",
        "train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).batch(16)\n",
        "test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).batch(4)\n",
        "val_ds_fmnist = tf.data.Dataset.from_tensor_slices((X_val_fmnist, y_val_fmnist)).batch(2)"
      ],
      "metadata": {
        "id": "K4tYXDCfcHp1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution With L1 Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
        "    self.W_h1 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W_h2 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3]))\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden3]))\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W_h1, self.W_h2, self.W2, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true)) + \\\n",
        "        (tf.reduce_sum(tf.abs(self.W1)) + tf.reduce_sum(tf.abs(self.W_h1)) + tf.reduce_sum(tf.abs(self.W_h2))+tf.reduce_sum(tf.abs(self.W2)))\n",
        "    return loss\n",
        "    \n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    # optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam')\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # Compute values in hidden layer\n",
        "    what_i = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat_i = tf.nn.relu(what_i)\n",
        "    what_h1 = tf.matmul(hhat_i, self.W_h1) + self.b2\n",
        "    hhat_h1 = tf.nn.relu(what_h1)\n",
        "    what_h2 = tf.matmul(hhat_h1, self.W_h2) + self.b3\n",
        "    hhat_h2 = tf.nn.relu(what_h2)\n",
        "\n",
        "    \n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    output = tf.matmul(hhat_h2, self.W2) + self.b4\n",
        "    output = tf.nn.softmax(output)\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output\n",
        "\n",
        "  # Calculate standard error\n",
        "  def stderr(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "    return std_err \n",
        "\n",
        " # Calculate variance error\n",
        "  def var(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    variance = (std_dev**2) # calculate variance\n",
        "    return variance \n",
        "    \n",
        "  def cat_accuracy(self, y_pred,y_true):\n",
        "    return tf.cast(tf.equal(tf.argmax(y_true, axis=-1),tf.argmax(y_pred, axis=-1)),tf.keras.backend.floatx())\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPVUu0YDa-_"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moAeRMJ56kr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec54d8c7-48aa-4911-dbf7-d57dc5201fd5"
      },
      "source": [
        "# Initialize model using CPU MNIST Data with L1 regularization\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='cpu')\n",
        "\n",
        "time_start = time.time()\n",
        "acc_mnist=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(seed)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_mnist.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], (100-(np.abs(np.sum(np.abs(accuracy)))/accuracy.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 5084.5445714285715, Accuracy:= 99.95\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 18.948426339285714, Accuracy:= 99.8\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.278661830357143, Accuracy:= 99.85\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278641741071429, Accuracy:= 99.8\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278591517857143, Accuracy:= 99.8\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278595982142857, Accuracy:= 99.85\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.2786015625, Accuracy:= 99.9\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.2786015625, Accuracy:= 99.85\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.2786015625, Accuracy:= 99.8\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.7\n",
            "\n",
            "Total time taken (in seconds): 1518.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMFAuH18Ve0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "accb4c56-9bd6-405e-c681-b95006d6cc37"
      },
      "source": [
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "acc_mnist_gpu=[]\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_mnist_gpu=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_mnist_gpu=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_mnist_gpu.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_mnist_gpu)))/accuracy_mnist_gpu.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 4325.573\n",
            "Number of Epoch = 2 - Average MSE:= 27.723109375\n",
            "Number of Epoch = 3 - Average MSE:= 12.409765625\n",
            "Number of Epoch = 4 - Average MSE:= 7.18881298828125\n",
            "Number of Epoch = 5 - Average MSE:= 4.785166015625\n",
            "Number of Epoch = 6 - Average MSE:= 3.5824267578125\n",
            "Number of Epoch = 7 - Average MSE:= 2.8207646484375\n",
            "Number of Epoch = 8 - Average MSE:= 2.42839990234375\n",
            "Number of Epoch = 9 - Average MSE:= 2.052015625\n",
            "Number of Epoch = 10 - Average MSE:= 1.837486572265625\n",
            "\n",
            "Total time taken (in seconds): 4.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4lsqPhB6Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df252e0-bc23-4ff6-cf45-7d3a546b03da"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output)\n",
        "acc_mnist_default=[]\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_mnist_default=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "    accuracy_mnist_default=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_mnist_default.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_mnist_default)))/accuracy_mnist_default.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.75\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.9\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.8\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.8\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.9\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.75\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.9\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.85\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.85\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278602678571428, Accuracy:= 99.85\n",
            "\n",
            "Total time taken (in seconds): 1255.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkaUg-TY7GdV",
        "outputId": "9dba401c-fdf9-4db8-9c93-1434710edc52"
      },
      "source": [
        "#TPU mode on MNIST data with L1 Regularization\n",
        "mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='tpu')\n",
        "\n",
        "print(\"TPU Model MNIST Data With L1 Regularization\")\n",
        "acc_mnist_tpu=[]\n",
        "time_start = time.time()\n",
        "accuracy_mnist_tpu=0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_mnist_tpu=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_mnist_tpu.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_mnist_tpu)))/accuracy_mnist_tpu.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU Model MNIST Data With L1 Regularization\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 5070.731428571428, Accuracy:= 100.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 18.52819642857143, Accuracy:= 99.95\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.27875892857143, Accuracy:= 99.8\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278792410714285, Accuracy:= 99.8\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278791294642858, Accuracy:= 99.9\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278829241071428, Accuracy:= 99.75\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.278822544642857, Accuracy:= 99.9\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.278822544642857, Accuracy:= 99.85\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.2788125, Accuracy:= 99.85\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278808035714286, Accuracy:= 99.85\n",
            "\n",
            "Total time taken (in seconds): 1713.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU FMNIST Data with L1 regularization\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='cpu')\n",
        "\n",
        "time_start = time.time()\n",
        "acc_fmnist_cpu=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_fmnist_cpu=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(20)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy_fmnist_cpu=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_fmnist_cpu.append(np.sum(loss_total) / Xtrain_fmnist.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_fmnist_cpu)))/accuracy_fmnist_cpu.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IS8_NhjnICH",
        "outputId": "c9f2e6e3-52ef-47e3-e746-3ef43e5efe6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 5084.497714285714, Accuracy:= 99.85\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 18.948245535714285, Accuracy:= 99.9\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.278693080357144, Accuracy:= 99.85\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278678571428571, Accuracy:= 99.8\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278678571428571, Accuracy:= 99.95\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278678571428571, Accuracy:= 99.85\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.278690848214286, Accuracy:= 99.95\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.278690848214286, Accuracy:= 100.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.278690848214286, Accuracy:= 99.95\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278690848214286, Accuracy:= 99.9\n",
            "\n",
            "Total time taken (in seconds): 1333.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU FMNIST Data with L1 regularization\n",
        "\n",
        "mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "acc_fmnist_gpu=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_fmnist_gpu=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(20)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_fmnist_cpu=mlp_on_gpu.cat_accuracy(preds, outputs)\n",
        "  acc_fmnist_gpu.append(np.sum(loss_total) / Xtrain_fmnist.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_fmnist_gpu)))/accuracy_fmnist_gpu.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "id": "rs9gY0E3nIEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using CPU FMNIST Data with L1 regularization\n",
        "\n",
        "mlp_on_tpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='tpu')\n",
        "\n",
        "time_start = time.time()\n",
        "acc_fmnist_tpu=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_fmnist_tpu=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(20)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_tpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_tpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_tpu.loss(preds, outputs)\n",
        "    mlp_on_tpu.backward(inputs, outputs)\n",
        "    accuracy_fmnist_tpu=mlp_on_tpu.cat_accuracy(preds, outputs)\n",
        "  acc_fmnist_tpu.append(np.sum(loss_total) / Xtrain_fmnist.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_fmnist_tpu)))/accuracy_fmnist_tpu.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8gpMWaenIGY",
        "outputId": "81cc9956-dab2-4733-aac2-9bc4866370c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 5071.617142857142, Accuracy:= 99.95\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 18.821868303571428, Accuracy:= 99.85\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.278353794642857, Accuracy:= 99.95\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278410714285714, Accuracy:= 99.8\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278410714285714, Accuracy:= 99.95\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278409598214285, Accuracy:= 99.85\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.278410714285714, Accuracy:= 99.95\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.278410714285714, Accuracy:= 99.8\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.278410714285714, Accuracy:= 99.95\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.9\n",
            "\n",
            "Total time taken (in seconds): 1356.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Default mode FMNIST Data Default\n",
        "\n",
        "mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output)\n",
        "acc_fmnist_default=[]\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_fmnist_default=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(20)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "    accuracy_fmnist_default=mlp_on_cpu.cat_accuracy(preds, outputs)\n",
        "  acc_fmnist_default.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], (100-(np.abs(np.sum(np.abs(accuracy_fmnist_default)))/accuracy_fmnist_default.shape[0]))))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0uV_IVnILz",
        "outputId": "a7c71ae8-f427-410a-fb2e-f2580796504f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.85\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.95\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.9\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.9\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.95\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.85\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.85\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.85\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.9\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 14.278411830357143, Accuracy:= 99.9\n",
            "\n",
            "Total time taken (in seconds): 1299.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## One Step Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda24cef-9e05-4f59-8a5d-54617c0002ce"
      },
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 8.9170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "from numpy import sqrt\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in test_ds:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mds2Y2SPqcbO",
        "outputId": "6ba469ae-5e20-4d79-f1af-0fc309ea28f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 8.9170\n",
            "Accuracy: 10.0286\n",
            "Standard Error: 0.0003\n",
            "Variance: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "from numpy import sqrt\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "acc = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "# Calculate\n",
        "for inputs, outputs in test_ds_fmnist:\n",
        "\n",
        "  preds = mlp_on_cpu.forward(inputs) # Prediction\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds,outputs) # Loss\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/Xtest_fmnist.shape[0])*100.0\n",
        "print('Inference 1st')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/Xtrain_fmnist.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emWCTwGyrDZt",
        "outputId": "c5bc13f1-fe54-4d03-a605-728c1c37c13a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 8.9170\n",
            "Accuracy: 10.0571\n",
            "Standard Error: 0.0003\n",
            "Variance: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve (with errors)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "iterations = [1,2,3,4,5,6,7,8,9,10]\n",
        "errors = np.squeeze(acc_mnist)\n",
        "# errors_gpu = np.squeeze(acc_mnist_gpu)\n",
        "errors_tpu = np.squeeze(acc_mnist_tpu)\n",
        "errors_default = np.squeeze(acc_mnist_default)\n",
        "plt.plot(iterations,errors,label='MNIST L1')\n",
        "# plt.plot(iterations,errors_gpu,label='MNIST L1 GPU')\n",
        "plt.plot(iterations,errors_tpu,label='Fashion MNIST TPU')\n",
        "plt.plot(iterations,errors_default,label='Fashion MNIST Default')\n",
        "plt.ylabel('errors')\n",
        "plt.xlabel('iterations ')\n",
        "plt.title(\"MNIST L1 Regularization\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1Hit0DOGHj-Q",
        "outputId": "4f0b4444-168c-43a8-ff9e-99c6abf721c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve (with errors)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "iterations = [1,2,3,4,5,6,7,8,9,10]\n",
        "errors = np.squeeze(acc_fmnist_cpu)\n",
        "# errors_gpu = np.squeeze(acc_mnist_gpu)\n",
        "errors_tpu = np.squeeze(acc_fmnist_tpu)\n",
        "errors_default = np.squeeze(acc_fmnist_default)\n",
        "plt.plot(iterations,errors,label='MNIST L1')\n",
        "# plt.plot(iterations,errors_gpu,label='MNIST L1 GPU')\n",
        "plt.plot(iterations,errors_tpu,label='Fashion MNIST TPU')\n",
        "plt.plot(iterations,errors_default,label='Fashion MNIST Default')\n",
        "plt.ylabel('errors')\n",
        "plt.xlabel('iterations ')\n",
        "plt.title(\"Fashion MNIST L1 Regularization\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GJkWlHFyN66l",
        "outputId": "926bfb81-8364-4965-9c1a-7b1b3dee6acf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oRaIKypyer_q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}