{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Em2vA9hpX08w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import keras\n",
        "import time\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "from keras.datasets import fashion_mnist\n",
        "from numpy import sqrt\n",
        "\n",
        "seed=97238684\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "# np.random.seed(1234)\n",
        "# tf.random.set_seed(1234)\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAl1_LRbX66t",
        "outputId": "c40b037e-8976-4a3f-ccc6-ca2454c719d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the MNIST dataset and define train, test and validation sets"
      ],
      "metadata": {
        "id": "Hc72l4CIl3Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_input = 784\n",
        "size_hidden1 = 512\n",
        "size_hidden2 = 256\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "starter_learning_rate = 0.001\n",
        "regularizer_rate = 0.1"
      ],
      "metadata": {
        "id": "wNoxeOiLX8Fz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the FMNIST dataset and define train, test and validation sets\n"
      ],
      "metadata": {
        "id": "Xm19Eynul9Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=(1-train_ratio))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=((test_ratio/(validation_ratio+test_ratio))))\n",
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqGE6f98X9aq",
        "outputId": "6da2a40f-e855-40bd-8951-e9252221c356"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshape the train, test and validation sets (MNIST)"
      ],
      "metadata": {
        "id": "12CGlYQdmAki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(Xtrain_fmnist, ytrain_fmnist), (Xtest_fmnist, ytest_fmnist) = fashion_mnist.load_data()\n",
        "X_fmnist = np.concatenate([Xtrain_fmnist, Xtest_fmnist])\n",
        "y_fmnist = np.concatenate([ytrain_fmnist, ytest_fmnist])\n",
        "\n",
        "Xtrain_fmnist, X_val_fmnist, ytrain_fmnist, y_val_fmnist = train_test_split(X_fmnist, y_fmnist, test_size=(1-train_ratio))\n",
        "X_val_fmnist, Xtest_fmnist, y_val_fmnist, ytest_fmnist = train_test_split(X_val_fmnist, y_val_fmnist, test_size=((test_ratio/(validation_ratio+test_ratio))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbQcH_RX_Fg",
        "outputId": "86953278-b39a-4b74-b2a1-816b33694a72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = np.reshape(X_train, (56000, 784))\n",
        "X_test = np.reshape(X_test, (-1, 784))\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255\n",
        "X_val = np.reshape(X_val, (7000,784))\n",
        "X_val=X_val/255.0\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "y_train = tf.one_hot(y_train,10)\n",
        "y_test = tf.one_hot(y_test,10)"
      ],
      "metadata": {
        "id": "1vJ2VWcBYCG4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshape the train, test and validation sets (FMNIST)"
      ],
      "metadata": {
        "id": "wxiWeLHfmK8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_fmnist = np.reshape(X_train, (56000, 784))\n",
        "Xtest_fmnist = np.reshape(X_test, (-1, 784))\n",
        "Xtrain_fmnist = Xtrain_fmnist.astype(float) / 255\n",
        "Xtest_fmnist = Xtest_fmnist.astype(float) / 255\n",
        "X_val_fmnist = np.reshape(X_val_fmnist, (7000,784))\n",
        "X_val_fmnist=X_val_fmnist.astype(float) /255.0\n",
        "ytrain_fmnist = tf.one_hot(ytrain_fmnist,10)\n",
        "ytest_fmnist = tf.one_hot(ytest_fmnist,10)"
      ],
      "metadata": {
        "id": "DdPE9rmHYDlJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(Xtrain_fmnist.shape, ytrain_fmnist.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xttQ7kYPYFAb",
        "outputId": "d4188da0-7829-4711-9139-e0825fbff078"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784) (56000, 10)\n",
            "(56000, 784) (56000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split MNIST dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(2)"
      ],
      "metadata": {
        "id": "scP6RpRtYGYZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split FMNIST dataset into batches\n",
        "train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).batch(16)\n",
        "test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).batch(4)\n",
        "val_ds_fmnist = tf.data.Dataset.from_tensor_slices((X_val_fmnist, y_val_fmnist)).batch(2)"
      ],
      "metadata": {
        "id": "u1qMinh1YIJX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build MLP using Eager Execution with Dropout"
      ],
      "metadata": {
        "id": "pTux5J5FmPlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
        "    self.W_h1 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W_h2 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3]))\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden3]))\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W_h1, self.W_h2, self.W2, self.b1, self.b2, self.b3, self.b4]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true)) \\\n",
        "    #     + regularizer_rate*(tf.reduce_sum(tf.square(self.b1)) + tf.reduce_sum(tf.square(self.b2)) + \\\n",
        "    #                         tf.reduce_sum(tf.square(self.b3)) + tf.reduce_sum(tf.square(self.b4)) + \\\n",
        "    #                         tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.W_h1) + tf.nn.l2_loss(self.W_h2) + tf.nn.l2_loss(self.W2) )\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true))\n",
        "    # return loss\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # Compute values in hidden layer\n",
        "    what_i = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat_i = tf.nn.relu(what_i)\n",
        "    drop_out = tf.nn.dropout(hhat_i, 0.2)\n",
        "    what_h1 = tf.matmul(drop_out, self.W_h1) + self.b2\n",
        "    hhat_h1 = tf.nn.relu(what_h1)\n",
        "    drop_out1 = tf.nn.dropout(hhat_h1, 0.2)\n",
        "    what_h2 = tf.matmul(drop_out1, self.W_h2) + self.b3\n",
        "    hhat_h2 = tf.nn.relu(what_h2)\n",
        "    drop_out2 = tf.nn.dropout(hhat_h2, 0.2)\n",
        "\n",
        "\n",
        "    output = tf.matmul(drop_out2, self.W2) + self.b4\n",
        "    output = tf.nn.softmax(output)\n",
        "   \n",
        "    return output\n",
        "\n",
        "    # Calculate standard error\n",
        "  def stderr(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "    return std_err \n",
        "\n",
        " # Calculate variance error\n",
        "  def var(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    variance = (std_dev**2) # calculate variance\n",
        "    return variance \n"
      ],
      "metadata": {
        "id": "fn998WUdYJq9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "GLWUJrwxmVgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "CCvojHHaYRpX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU MNIST Data on train data\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using CPU MNIST Data Without Regularization on Train data\")\n",
        "time_start = time.time()\n",
        "acc_mnist_train=[]\n",
        "acc_mnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_train=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy_train=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "  acc_mnist_train.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], accuracy_train.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVuosvrAYS55",
        "outputId": "73a8a4a5-04ba-4002-f380-c5c3384a680c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using CPU MNIST Data Without Regularization on Train data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.023666881016322545, Accuracy:= 8.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.023673001970563615, Accuracy:= 10.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.02369852120535714, Accuracy:= 7.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.023697906494140625, Accuracy:= 7.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.023660609654017856, Accuracy:= 12.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.023674894060407365, Accuracy:= 8.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.02369165257045201, Accuracy:= 10.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.02368571254185268, Accuracy:= 8.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.023649187360491073, Accuracy:= 11.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.023681348528180803, Accuracy:= 10.0\n",
            "\n",
            "Total time taken (in seconds): 132.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU MNIST Data With Dropout on Test data\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using GPU MNIST Data With Dropout on Test data\")\n",
        "time_start = time.time()\n",
        "acc_mnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_test=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy_test=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accuracy_test.update_state(preds, outputs)\n",
        "  acc_mnist_test.append(np.sum(loss_total) / X_test.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_test.shape[0], accuracy_test.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh6T0NjMYVjC",
        "outputId": "d4e0f27e-fe20-4edb-d5f4-ccabcf8e2f87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using GPU MNIST Data With Dropout on Test data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.5909325474330357, Accuracy:= 25.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.59166015625, Accuracy:= 25.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.5905032784598214, Accuracy:= 25.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.5897181222098214, Accuracy:= 25.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.5912550920758929, Accuracy:= 0.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.5900055106026786, Accuracy:= 0.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.5902905970982143, Accuracy:= 0.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.5898265904017858, Accuracy:= 25.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.58939794921875, Accuracy:= 25.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.5908976004464286, Accuracy:= 50.0\n",
            "\n",
            "Total time taken (in seconds): 374.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU MNIST Data With Dropout on Test data\n",
        "\n",
        "mlp_on_tpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='tpu')\n",
        "print(\"model using GPU MNIST Data With Dropout on Test data\")\n",
        "time_start = time.time()\n",
        "acc_mnist_test_tpu=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_test_tpu=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_tpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_tpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_tpu.backward(inputs, outputs)\n",
        "    accuracy_test_tpu=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accuracy_test_tpu.update_state(preds, outputs)\n",
        "  acc_mnist_test_tpu.append(np.sum(loss_total) / X_test.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_test.shape[0], accuracy_test_tpu.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ1fwnRmbwOt",
        "outputId": "927ee998-c4d7-4941-b040-c3544c881036"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using GPU MNIST Data With Dropout on Test data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.5912547433035714, Accuracy:= 25.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.5887556501116071, Accuracy:= 0.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.5899688197544642, Accuracy:= 25.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.5888635602678571, Accuracy:= 25.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.5900394112723214, Accuracy:= 25.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.5889372907366072, Accuracy:= 25.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.59061279296875, Accuracy:= 25.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.588923828125, Accuracy:= 25.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.5896847098214286, Accuracy:= 25.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.5887389090401786, Accuracy:= 25.0\n",
            "\n",
            "Total time taken (in seconds): 502.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU Fashion MNIST Data With Dropout on train data\n",
        "\n",
        "mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using GPU Fashion MNIST Data With Dropout on Train data\")\n",
        "time_start = time.time()\n",
        "acc_fmnist_train=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accu_train_fmnist=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accu_train_fmnist=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accu_train_fmnist.update_state(preds, outputs)\n",
        "  acc_fmnist_train.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], accu_train_fmnist.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCFRK-tQYfS7",
        "outputId": "02561bd0-9e2c-4ec4-bfdb-503aca7600c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using GPU Fashion MNIST Data With Dropout on Train data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.02361220223563058, Accuracy:= 12.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.023581202915736607, Accuracy:= 11.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.023590138026646206, Accuracy:= 9.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.023601412091936384, Accuracy:= 11.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.02361309596470424, Accuracy:= 18.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.023599321637834823, Accuracy:= 11.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.023613743373325894, Accuracy:= 9.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.02363609313964844, Accuracy:= 10.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.023594835553850446, Accuracy:= 13.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.02360697283063616, Accuracy:= 10.0\n",
            "\n",
            "Total time taken (in seconds): 121.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU Fashion MNIST Data With Dropout on train data\n",
        "\n",
        "mlp_on_tpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='tpu')\n",
        "print(\"model using TPU Fashion MNIST Data With Dropout on Test data\")\n",
        "time_start = time.time()\n",
        "\n",
        "acc_fmnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accu_test_fmnist=0\n",
        "  test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in test_ds_fmnist:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_tpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_tpu.loss(preds, outputs)\n",
        "    mlp_on_tpu.backward(inputs, outputs)\n",
        "    accu_test_fmnist=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accu_test_fmnist.update_state(preds, outputs)\n",
        "  acc_fmnist_test.append(np.sum(loss_total) / Xtest_fmnist.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtest_fmnist.shape[0], accu_test_fmnist.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CniNrkNnYfVS",
        "outputId": "01e22451-dc62-4499-90d6-896f507a4b36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using TPU Fashion MNIST Data With Dropout on Test data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.023594876970563616, Accuracy:= 10.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.023615543910435268, Accuracy:= 13.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.02356805637904576, Accuracy:= 9.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.023588668823242186, Accuracy:= 8.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.02359183829171317, Accuracy:= 12.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.023576119559151787, Accuracy:= 8.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.023568675449916296, Accuracy:= 6.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.023647859845842632, Accuracy:= 11.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.023590571812220983, Accuracy:= 13.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.023639277866908483, Accuracy:= 11.0\n",
            "\n",
            "Total time taken (in seconds): 21.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  # print(preds)\n",
        "  b = mlp_on_cpu.loss(preds, outputs)\n",
        "  standard_error = mlp_on_cpu.stderr(preds) \n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  Variance = mlp_on_cpu.var(preds) \n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference for Test Data With Dropout')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))\n",
        "\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMPzTc28YfXo",
        "outputId": "432313ca-d251-4de2-aff2-6c0b2d073590"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference for Test Data With Dropout\n",
            "Test MSE: 0.0739\n",
            "Accuracy: 9.7857\n",
            "Standard Error: 0.1500\n",
            "Variance: 0.0900\n",
            "Test MSE: 0.0739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve (with errors)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "iterations = [1,2,3,4,5,6,7,8,9,10]\n",
        "errors_train = np.squeeze(acc_mnist_train)\n",
        "errors_test = np.squeeze(acc_mnist_test)\n",
        "errors_train1 = np.squeeze(acc_fmnist_train)\n",
        "errors_test1 = np.squeeze(acc_fmnist_test)\n",
        "# errors_test2 = np.squeeze(acc_fmnist_test_tpu)\n",
        "plt.plot(iterations,errors_train,label='MNIST Train With Dropout')\n",
        "plt.plot(iterations,errors_test,label='MNIST Test With Dropout ')\n",
        "plt.plot(iterations,errors_train1,label='Fashion MNIST train With Dropout ')\n",
        "plt.plot(iterations,errors_test1,label='Fashion MNIST test With Dropout')\n",
        "# plt.plot(iterations,errors_test2,label='Fashion MNIST test With Dropout TPU')\n",
        "plt.ylabel('errors')\n",
        "plt.xlabel('iterations ')\n",
        "plt.title(\"MNIST and Fashion MNIST With Dropout\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QzLHe6dqYzT3",
        "outputId": "a5ff6c1f-003c-4026-c615-938b743281b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}