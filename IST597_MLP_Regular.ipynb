{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597_MLP_Regular.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_MLP_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import keras\n",
        "import time\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "from keras.datasets import fashion_mnist\n",
        "from numpy import sqrt\n",
        "\n",
        "seed=97238684\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "# np.random.seed(1234)\n",
        "# tf.random.set_seed(1234)\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-3kEaggcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2fe132-46c8-4b37-aae6-e82ac5a93eba"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the input, output and hidden layer sizes\n"
      ],
      "metadata": {
        "id": "xb2WcNmV5-pR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XlFnwho7D8"
      },
      "source": [
        "size_input = 784\n",
        "size_hidden1 = 512\n",
        "size_hidden2 = 256\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "starter_learning_rate = 0.001\n",
        "regularizer_rate = 0.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the MNIST dataset and define train, test and validation sets"
      ],
      "metadata": {
        "id": "KQ7xdM7L6TbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X = np.concatenate([X_train, X_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=(1-train_ratio))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=((test_ratio/(validation_ratio+test_ratio))))\n",
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTQoYKheokJe",
        "outputId": "ea9efa48-9425-4954-ba1f-df8c9fd24fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the FMNIST dataset and define train, test and validation sets"
      ],
      "metadata": {
        "id": "XkjF_wMO7wvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(Xtrain_fmnist, ytrain_fmnist), (Xtest_fmnist, ytest_fmnist) = fashion_mnist.load_data()\n",
        "X_fmnist = np.concatenate([Xtrain_fmnist, Xtest_fmnist])\n",
        "y_fmnist = np.concatenate([ytrain_fmnist, ytest_fmnist])\n",
        "\n",
        "Xtrain_fmnist, X_val_fmnist, ytrain_fmnist, y_val_fmnist = train_test_split(X_fmnist, y_fmnist, test_size=(1-train_ratio))\n",
        "X_val_fmnist, Xtest_fmnist, y_val_fmnist, ytest_fmnist = train_test_split(X_val_fmnist, y_val_fmnist, test_size=((test_ratio/(validation_ratio+test_ratio))))"
      ],
      "metadata": {
        "id": "LbYYMC4oKS4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshape the train, test and validation sets (MNIST)"
      ],
      "metadata": {
        "id": "GYCjFzjT6ZCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = np.reshape(X_train, (56000, 784))\n",
        "X_test = np.reshape(X_test, (-1, 784))\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255\n",
        "X_val = np.reshape(X_val, (7000,784))\n",
        "X_val=X_val/255.0\n",
        "X_val=tf.cast(X_val,dtype=tf.float32)\n",
        "y_train = tf.one_hot(y_train,10)\n",
        "y_test = tf.one_hot(y_test,10)"
      ],
      "metadata": {
        "id": "QTSjERuunupa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshape the train, test and validation sets (FMNIST)"
      ],
      "metadata": {
        "id": "5mOBLp8L75QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_fmnist = np.reshape(X_train, (56000, 784))\n",
        "Xtest_fmnist = np.reshape(X_test, (-1, 784))\n",
        "Xtrain_fmnist = Xtrain_fmnist.astype(float) / 255\n",
        "Xtest_fmnist = Xtest_fmnist.astype(float) / 255\n",
        "X_val_fmnist = np.reshape(X_val_fmnist, (7000,784))\n",
        "X_val_fmnist=X_val_fmnist.astype(float) /255.0\n",
        "ytrain_fmnist = tf.one_hot(ytrain_fmnist,10)\n",
        "ytest_fmnist = tf.one_hot(ytest_fmnist,10)"
      ],
      "metadata": {
        "id": "RkHsZLoAKyPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm23CzRihaW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a6ba14-d372-48be-a344-fc8dc89eec41"
      },
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(Xtrain_fmnist.shape, ytrain_fmnist.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784) (56000, 10)\n",
            "(56000, 784) (56000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_train: \",y_train)\n",
        "print(\"y_val: \",y_val)\n",
        "print(\"y_test: \",y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhDAOL_VhahJ",
        "outputId": "3651b5ff-a02f-4241-c5ca-a58ff9d832fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:  tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]], shape=(56000, 10), dtype=float32)\n",
            "y_val:  [4 2 6 ... 6 2 5]\n",
            "y_test:  tf.Tensor(\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]], shape=(7000, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2"
      },
      "source": [
        "# Split MNIST dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split FMNIST dataset into batches\n",
        "train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).batch(16)\n",
        "test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).batch(4)\n",
        "val_ds_fmnist = tf.data.Dataset.from_tensor_slices((X_val_fmnist, y_val_fmnist)).batch(2)"
      ],
      "metadata": {
        "id": "sta64VcTK-5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution without Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device \n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1]))\n",
        "    # Initialize weights between hidden layers\n",
        "    self.W_h1 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden1]))\n",
        "     # Initialize weights between hidden layers\n",
        "    self.W_h2 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize weights between hidden layer and output layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden2]))\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_hidden3]))\n",
        "    self.b4 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W_h1, self.W_h2, self.W2, self.b1, self.b2, self.b3, self.b4]\n",
        "\n",
        "\n",
        "        \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true)) \\\n",
        "    #     + regularizer_rate*(tf.reduce_sum(tf.square(self.b1)) + tf.reduce_sum(tf.square(self.b2)) + \\\n",
        "    #                         tf.reduce_sum(tf.square(self.b3)) + tf.reduce_sum(tf.square(self.b4)) + \\\n",
        "    #                         tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.W_h1) + tf.nn.l2_loss(self.W_h2) + tf.nn.l2_loss(self.W2) )\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true))\n",
        "    \n",
        "    # return loss\n",
        "    \n",
        "\n",
        "\n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    # optimizer = tf.keras.optimizers.Adam(\n",
        "    # learning_rate=0.001, epsilon=1e-07, amsgrad=False,\n",
        "    # name='Adam')\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "\n",
        "\n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    \n",
        "    # Compute values in hidden layer\n",
        "    what_i = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat_i = tf.nn.relu(what_i)\n",
        "    what_h1 = tf.matmul(hhat_i, self.W_h1) + self.b2\n",
        "    hhat_h1 = tf.nn.relu(what_h1)\n",
        "    what_h2 = tf.matmul(hhat_h1, self.W_h2) + self.b3\n",
        "    hhat_h2 = tf.nn.relu(what_h2)\n",
        "    what_out = tf.matmul(hhat_h2, self.W2) + self.b4\n",
        "    hhat = tf.nn.relu(what_out)\n",
        "    # Compute output\n",
        "    output_i = tf.matmul(hhat_i, self.W_h1) + self.b2\n",
        "    output_h1 = tf.matmul(hhat_h1, self.W_h2) + self.b3\n",
        "    output = tf.matmul(hhat_h2, self.W2) + self.b4\n",
        "    return output\n",
        "\n",
        " # Calculate standard error\n",
        "  def stderr(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "    return std_err \n",
        "\n",
        " # Calculate variance error\n",
        "  def var(self,y_pred):\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "    variance = (std_dev**2) # calculate variance\n",
        "    return variance \n",
        "\n",
        "  def cat_accuracy(self, y_pred,y_true):\n",
        "    return tf.cast(tf.equal(tf.argmax(y_true, axis=-1),tf.argmax(y_pred, axis=-1)),tf.keras.backend.floatx())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPVUu0YDa-_"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moAeRMJ56kr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af992cc-3c6f-46a0-ae14-b4bb1e4a083f"
      },
      "source": [
        "# Initialize model using GPU MNIST Data on train data\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using CPU MNIST Data Without Regularization on Train data\")\n",
        "time_start = time.time()\n",
        "acc_mnist_train=[]\n",
        "acc_mnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_train=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy_train=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "  acc_mnist_train.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0], accuracy_train.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using CPU MNIST Data Without Regularization on Train data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 13.457877232142858, Accuracy:= 80.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 4.502041294642857, Accuracy:= 89.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 3.181255859375, Accuracy:= 85.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 2.491190011160714, Accuracy:= 87.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 2.042404994419643, Accuracy:= 90.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 1.7421519252232143, Accuracy:= 89.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 1.5103563058035714, Accuracy:= 90.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 1.3378405412946428, Accuracy:= 88.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 1.1999453125, Accuracy:= 90.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 1.08328515625, Accuracy:= 92.0\n",
            "\n",
            "Total time taken (in seconds): 177.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMFAuH18Ve0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eec5f6c-55b0-4857-c121-2cd627964b64"
      },
      "source": [
        "# Initialize model using GPU MNIST Data on Test data\n",
        "\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using GPU MNIST Data Without Regularization on Test data\")\n",
        "time_start = time.time()\n",
        "acc_mnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accuracy_test=0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in test_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "    accuracy_test=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accuracy_test.update_state(preds, outputs)\n",
        "  acc_mnist_test.append(np.sum(loss_total) / X_test.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / X_test.shape[0], accuracy_test.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using GPU MNIST Data Without Regularization on Test data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 205.31421428571429, Accuracy:= 100.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 29.93509375, Accuracy:= 100.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 13.579109375, Accuracy:= 100.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 7.510904575892857, Accuracy:= 100.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 4.934040736607143, Accuracy:= 100.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 3.5423387276785716, Accuracy:= 100.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 2.5098758370535714, Accuracy:= 100.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 2.0056180245535713, Accuracy:= 100.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 1.60450390625, Accuracy:= 100.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 1.1582278878348213, Accuracy:= 100.0\n",
            "\n",
            "Total time taken (in seconds): 527.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU Fashion MNIST Data on train data\n",
        "\n",
        "mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "print(\"model using GPU Fashion MNIST Data Without Regularization on Train data\")\n",
        "time_start = time.time()\n",
        "acc_fmnist_train=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accu_train_fmnist=0\n",
        "  train_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtrain_fmnist, ytrain_fmnist)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in train_ds_fmnist:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accu_train_fmnist=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accu_train_fmnist.update_state(preds, outputs)\n",
        "  acc_fmnist_train.append(np.sum(loss_total) / X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtrain_fmnist.shape[0], accu_train_fmnist.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-2kgoT4N_ZT",
        "outputId": "6527001f-ebab-4e4c-e13b-b9b3d4062571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using GPU Fashion MNIST Data Without Regularization on Train data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 1.7145040457589287, Accuracy:= 13.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 1.2123295200892856, Accuracy:= 7.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 1.0037972237723214, Accuracy:= 5.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.8362370954241072, Accuracy:= 9.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.7329169224330357, Accuracy:= 9.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.6850256696428572, Accuracy:= 7.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.6340092075892857, Accuracy:= 8.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.5678643275669643, Accuracy:= 10.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.5247691824776786, Accuracy:= 14.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.49849672154017854, Accuracy:= 6.0\n",
            "\n",
            "Total time taken (in seconds): 173.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize model using GPU Fashion MNIST Data on test data\n",
        "\n",
        "# mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "# print(\"model using GPU Fashion MNIST Data Without Regularization on Test data\")\n",
        "# time_start = time.time()\n",
        "# acc_fmnist_test=[]\n",
        "# for epoch in range(NUM_EPOCHS):\n",
        "#   loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "#   lt = 0\n",
        "#   accu_test_fmnist=0\n",
        "#   test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "#   for inputs, outputs in test_ds_fmnist:\n",
        "#     preds = mlp_on_gpu.forward(inputs)\n",
        "#     loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "#     lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "#     mlp_on_gpu.backward(inputs, outputs)\n",
        "#     accu_test_fmnist=tf.keras.metrics.CategoricalAccuracy()\n",
        "#     accu_test_fmnist.update_state(preds, outputs)\n",
        "#   acc_fmnist_test.append(np.sum(loss_total) / Xtest_fmnist.shape[0])\n",
        "#   print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtest_fmnist.shape[0], accu_test_fmnist.result()*100))\n",
        "# time_taken = time.time() - time_start\n",
        "\n",
        "# print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "# #For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "id": "S0MX2aDiOAFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model using GPU Fashion MNIST Data on train data\n",
        "\n",
        "mlp_on_tpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='tpu')\n",
        "print(\"model using TPU Fashion MNIST Data Without Regularization on Test data\")\n",
        "time_start = time.time()\n",
        "\n",
        "acc_fmnist_test=[]\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  accu_test_fmnist=0\n",
        "  test_ds_fmnist = tf.data.Dataset.from_tensor_slices((Xtest_fmnist, ytest_fmnist)).shuffle(25, seed=epoch*(seed)).batch(100)\n",
        "  for inputs, outputs in test_ds_fmnist:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_tpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_tpu.loss(preds, outputs)\n",
        "    mlp_on_tpu.backward(inputs, outputs)\n",
        "    accu_test_fmnist=tf.keras.metrics.CategoricalAccuracy()\n",
        "    accu_test_fmnist.update_state(preds, outputs)\n",
        "  acc_fmnist_test.append(np.sum(loss_total) / Xtest_fmnist.shape[0])\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {}, Accuracy:= {}'.format(epoch + 1, np.sum(loss_total) / Xtest_fmnist.shape[0], accu_test_fmnist.result()*100))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbKf1uLmN_bm",
        "outputId": "1dca900a-97ee-4ec8-b605-8373350c46cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model using TPU Fashion MNIST Data Without Regularization on Test data\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 5.800516183035715, Accuracy:= 11.0\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 5.8005150669642855, Accuracy:= 12.0\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 5.800513950892857, Accuracy:= 11.0\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 5.800513392857143, Accuracy:= 9.0\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 5.8005150669642855, Accuracy:= 11.0\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 5.800515625, Accuracy:= 12.0\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 5.800514508928571, Accuracy:= 11.0\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 5.800514508928571, Accuracy:= 9.0\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 5.800515625, Accuracy:= 10.0\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 5.800515625, Accuracy:= 9.0\n",
            "\n",
            "Total time taken (in seconds): 28.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## One Step Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c84569-367f-410e-8129-333e62e43a70"
      },
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  # print(preds)\n",
        "  b = mlp_on_cpu.loss(preds, outputs)\n",
        "  standard_error = mlp_on_cpu.stderr(preds) \n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "  Variance = mlp_on_cpu.var(preds) \n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/X_test.shape[0])*100.0\n",
        "print('Inference for Test Data Regular')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/X_train.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))\n",
        "\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 0.3104\n",
            "Accuracy: 81.2000\n",
            "Standard Error: 394.6757\n",
            "Variance: 623075.6002\n",
            "Test MSE: 0.3104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "acc_preds = tf.Variable(0,dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds_fmnist:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  # print(preds)\n",
        "  b = mlp_on_cpu.loss(preds, outputs)\n",
        "  standard_error = mlp_on_cpu.stderr(preds) # Standard error\n",
        "  # print(b)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "  Variance = mlp_on_cpu.var(preds) # Variance\n",
        "\n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])==tf.argmax(outputs[i]):\n",
        "      acc_preds = acc_preds + 1.0\n",
        "acc = (acc_preds/Xtest_fmnist.shape[0])*100.0\n",
        "print('Inference Fashion MNIST Test data Regular')\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy())/Xtest_fmnist.shape[0]))\n",
        "print('Accuracy: {:.4f}'.format(acc))\n",
        "print('Standard Error: {:.4f}'.format(standard_error))\n",
        "print('Variance: {:.4f}'.format(Variance))\n",
        "\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / Xtest_fmnist.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhxuUtDGbCKj",
        "outputId": "302af873-b57d-4775-e7b0-c240a4903c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference 1st\n",
            "Test MSE: 3.0099\n",
            "Accuracy: 10.0857\n",
            "Standard Error: 4.5629\n",
            "Variance: 83.2797\n",
            "Test MSE: 3.0099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve (with errors)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "iterations = [1,2,3,4,5,6,7,8,9,10]\n",
        "errors_train = np.squeeze(acc_mnist_train)\n",
        "errors_test = np.squeeze(acc_mnist_test)\n",
        "errors_train1 = np.squeeze(acc_fmnist_train)\n",
        "errors_test1 = np.squeeze(acc_fmnist_test)\n",
        "plt.plot(iterations,errors_train,label='MNIST Train Regular')\n",
        "plt.plot(iterations,errors_test,label='MNIST Test Regular ')\n",
        "plt.plot(iterations,errors_train1,label='Fashion MNIST train Regular ')\n",
        "plt.plot(iterations,errors_test1,label='Fashion MNIST test Regular')\n",
        "plt.ylabel('errors')\n",
        "plt.xlabel('iterations ')\n",
        "plt.title(\"MNIST Regular\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "A21B--RsYV0u",
        "outputId": "45649805-5f5c-47d3-dd56-a4e308fc681c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}